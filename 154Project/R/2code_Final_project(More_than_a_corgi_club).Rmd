---
title: "Final project (Jin Kweon and Jiyoon Clover Jeong)"
author: "Jin Kweon and Clover Jeong"
date: "11/22/2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rpart) #decision tree
library(rpart.plot) # plotting decision tree
library(mlr, warn.conflicts = T) #missing values imputation
library(missForest, warn.conflicts = T) #missing values imputation
library(mi, warn.conflicts = T) #missing values imputation
library(mice, warn.conflicts = T) #missing values imputation
library(VIM) #finding patterns of missing values
library(Hmisc) #missing values imputation
library(lattice)
library(arules) #discretize
library(lme4) #dummfiy
library(tree)
library(caret)
library(ROCR, warn.conflicts = T) # ROC curve
library(pROC, warn.conflicts = T) # Get the optimal threshold
library(randomForest)
options(scipen=999) #get rid of scientific notation 

```



#Preprocessing and Exploratory Data Analysis 

###a) Missing values
```{r EDA}
train <- read.table("../data/rawdata/adult.data.txt", sep = ",", na.strings = "?",
                    strip.white = T)
test <- read.table("../data/rawdata/adult.test.txt", sep = ",", na.strings = "?",
                   strip.white = T)

dim(train)
dim(test)

colnames(train) <- c("age", "workclass", "fnlwgt", "education", "education-num",
                     "marital-status", "occupation", "relationship", "race", "sex",
                     "capital-gain", "capital-loss", "hours-per-week", "native-country", "income")

colnames(test) <- c("age", "workclass", "fnlwgt", "education", "education-num",
                     "marital-status", "occupation", "relationship", "race", "sex",
                     "capital-gain", "capital-loss", "hours-per-week", "native-country", "income")

#Find missing values and NAs for training set.
for(i in 1:ncol(train)){
  cat("<names of NA rows in", colnames(train)[i], "variable>", "\n")
  cat(rownames(train)[is.na(train[,i])], "\n")
  cat("Number of NA values:  ", length(rownames(train)[is.na(train[,i])]),"\n")
  print("======================================")
  print("======================================")
  
  cat("<names of rows contain missing values in", colnames(train)[i], "variable>", "\n")
  cat(rownames(train[which(train[,i] == ""),]), "\n")
  cat("Number of Missing values :  ", length(rownames(train[which(train[,i] == ""),])), "\n")
  print("======================================")
  print("======================================")
  
  cat("<names of rows contain ? values in", colnames(train)[i], "variable>", "\n")
  cat(rownames(train[which(train[,i] == " ?"),]), "\n")
  cat("Number of ? values :  ", length(rownames(train[which(train[,i] == " ?"),])), "\n")
  print("======================================")
  print("======================================")
}

# emptytrain <- c()
# for(i in 1:ncol(train)){
#   emptytrain[i] <- sum(train[,i] == "?")
# }
# emptytrain

#Find missing values and NAs for testing set.
for(i in 1:ncol(test)){
  cat("<names of NA rows in", colnames(test)[i], "variable>", "\n")
  cat(rownames(test)[is.na(test[,i])], "\n")
  cat("Number of NA values:  ", length(rownames(test)[is.na(test[,i])]),"\n")
  print("======================================")
  print("======================================")
  
  cat("<names of rows contain missing values in", colnames(test)[i], "variable>", "\n")
  cat(rownames(test[which(test[,i] == ""),]), "\n")
  cat("Number of Missing values :  ", length(rownames(test[which(test[,i] == ""),])), "\n")
  print("======================================")
  print("======================================")
  
  cat("<names of rows contain ? values in", colnames(test)[i], "variable>", "\n")
  cat(rownames(test[which(test[,i] == " ?"),]), "\n")
  cat("Number of ? values :  ", length(rownames(test[which(test[,i] == " ?"),])), "\n")
  print("======================================")
  print("======================================")
}

# emptytest <- c()
# for(i in 1:ncol(test)){
#   emptytest[i] <- sum(test[,i] == "?")
# }
# emptytest


#Get percentage of missing values
apply(train, 2, function(x) sum(is.na(x))/length(x))*100
apply(test, 2, function(x) sum(is.na(x))/length(x))*100


#MICE package to see the pattern 
md.pattern(train)
plot <- aggr(train, col = c('blue','yellow'),
                    numbers = TRUE, sortVars = TRUE,
                    labels = names(train), cex.axis=.7,
                    gap = 2, ylab=c("Missing data","Pattern"))

md.pattern(test)
plot <- aggr(test, col = c('blue','yellow'),
                    numbers = TRUE, sortVars = TRUE,
                    labels = names(test), cex.axis=.7,
                    gap = 2, ylab=c("Missing data","Pattern"))



# Hmisc package to impute missing values
# ww <- aregImpute(~ age + workclass + fnlwgt + education + `education-num` + `marital-status` +
#                    occupation + relationship + race + sex + `capital-gain` + `capital-loss` +
#                    `hours-per-week` + income,
#                  data = train, n.impute = 5, group = "income")



#mlr package to impute missing values
# newworkclass <- impute(train[,2], classes = list(factor = imputeMode(), integer = imputeMean()), dummy.classes = c("integer","factor"), dummy.type = "numeric")
# 
# newoccupation <- impute(train[,7], classes = list(factor = imputeMode(), integer = imputeMean()), dummy.classes = c("integer","factor"), dummy.type = "numeric")
# 
# newcountry <- impute(train[,14], classes = list(factor = imputeMode(), integer = imputeMean()), dummy.classes = c("integer","factor"), dummy.type = "numeric")



#missForest package to impute missing values
# foresting <- missForest(train, maxiter = 5, ntree = 100)
# foresting$OOBerror
# newtrain <- foresting$ximp
# write.csv(newtrain, file = "../data/cleandata/newtrain.csv", col.names = T, row.names = F)

newtrain <- read.csv("../data/cleandata/newtrain.csv", header = T)
dim(newtrain)

# foresting2 <- missForest(test, maxiter = 5, ntree = 100)
# foresting2$OOBerror
# newtest <- foresting2$ximp
# write.csv(newtest, file = "../data/cleandata/newtest.csv", col.names = T, row.names = F)
newtest <- read.csv("../data/cleandata/newtest.csv", header = T)
dim(newtest)



#Check whether the data is messed up while imputing missing values
#They should never show 0, as we are supposed to see only missing value has been changed...
#Compare NA with new number in new data set should show NA, not 0.
t <- matrix(0, 1, ncol(train))
for(i in 1:20){
  a <- sample.int(nrow(newtrain), 1)
  t <- rbind(t, (newtrain[a,] == train[a,]))
}
t <- t[-1,]
t

t2 <- matrix(0, 1, ncol(test))
for(i in 1:20){
  a <- sample.int(nrow(newtest), 1)
  t2 <- rbind(t2, (newtest[a,] == test[a,]))
}
t2 <- t2[-1,]
t2
```

$\\$

$\\$

###b) 2 - 5 EDAs
```{r}
#See structure and summaries before removing outliers
str(newtest)
summary(newtest)

str(newtrain)
summary(newtrain)


#Deal with outliers for training sets
continuouscol <- c(1, 3, 5, 11, 12, 13) #subset continous variables

par(mfrow = c(2, 3))
for(i in continuouscol){
  boxplot(newtrain[,i], main = paste("boxplot for", colnames(newtrain[i])),
          xlab = colnames(newtrain[i]))
}

for(i in continuouscol){
  den_acc <- density(newtrain[,i], adjust = 1)
  plot(den_acc, main = paste("density plot for", colnames(newtrain[i])))
  polygon(den_acc, col = "red", border = "blue")
}

outlierstrain <- list()
for(i in continuouscol){
  outliers <- boxplot.stats(newtrain[,i])$out
  numbers <- length(outliers)
  outlierstrain[[i]] <- list(outliers, numbers)
}
head(outlierstrain)

fnlwgttrainout <- tail(order(rank(newtrain[,3])), 15)
fnlout <- c()
for(i in 1:length(fnlwgttrainout)){
  fnlout[i] <- newtrain[fnlwgttrainout[i], 3]
}

#head(order(rank(newtrain[,5])))

table(newtrain[,11])
gainout <- tail(order(rank(newtrain[,11])), 159)

#Outliers removing for training sets.
dim(newtrain)
newtrain <- newtrain[-gainout, ]
dim(newtrain)



#Deal with outliers for testing sets
for(i in continuouscol){
  boxplot(newtest[,i], main = paste("boxplot for", colnames(newtest[i])),
          xlab = colnames(newtest[i]))
}

for(i in continuouscol){
  den_acc <- density(newtest[,i], adjust = 1)
  plot(den_acc, main = paste("density plot for", colnames(newtest[i])))
  polygon(den_acc, col = "red", border = "blue")
}

outlierstest <- list()
for(i in continuouscol){
  outliers <- boxplot.stats(newtest[,i])$out
  numbers <- length(outliers)
  outlierstest[[i]] <- list(outliers, numbers)
}
head(outlierstest)

table(newtest[,11])
gainout <- tail(order(rank(newtest[,11])), 85)

#Outliers removing for training sets.
dim(newtest)
newtest <- newtest[-gainout, ]
dim(newtest)




#Plots after removing outliers training
for(i in continuouscol){
  boxplot(newtrain[,i], main = paste("boxplot for", colnames(newtrain[i]), "-outliers removed"),
          xlab = colnames(newtrain[i]))
}

for(i in continuouscol){
  den_acc <- density(newtrain[,i], adjust = 1)
  plot(den_acc, main = paste("density plot for", colnames(newtrain[i]), "-outliers removed"))
  polygon(den_acc, col = "red", border = "blue")
}

#Plots after removing outliers testing
for(i in continuouscol){
  boxplot(newtest[,i], main = paste("boxplot for", colnames(newtest[i]), "-outliers removed"),
          xlab = colnames(newtest[i]))
}

for(i in continuouscol){
  den_acc <- density(newtest[,i], adjust = 1)
  plot(den_acc, main = paste("density plot for", colnames(newtest[i]), "-outliers removed"))
  polygon(den_acc, col = "red", border = "blue")
}
```

$\\$

$\\$

###c) 6 - 8 EDAs
```{r}
#See structure and summaries after removing outliers
str(newtest)
summary(newtest)

str(newtrain)
summary(newtrain)


#Analyzing/checking before discretizing
table(newtrain[,14])
table(newtest[,14])

plot(newtrain$education)
plot(newtrain$occupation)
plot(newtrain$native.country)

plot(newtest$education)
plot(newtest$occupation)
plot(newtest$native.country)


#Discretize training set
# discretetrainage <- discretize(newtrain$age, method = "interval", categories = 10)
# discretetrainfnlwgt <- discretize(newtrain$fnlwgt, method = "interval", categories = 10)
# discretetrainedunum <- discretize(newtrain$education.num, method = "interval", categories = 10)
# discretetraingain <- discretize(newtrain$capital.gain, method = "interval", categories = 10)
# discretetrainloss <- discretize(newtrain$capital.loss, method = "interval", categories = 10)
# discretetrainhours <- discretize(newtrain$hours.per.week, method = "interval", categories = 10)

countrydis <- function(vector){
  len <- length(vector)
  for(i in 1:len){
      if(vector[i] == "United-States"){
        vector[i] <- vector[i]
      }else if(vector[i] == "Mexico"){
        vector[i] <- vector[i]
      }else if(vector[i] == "Philippines"){
        vector[i] <- vector[i]
      }else{
        vector[i] <- "other_countries"
      }
  }
  return(vector)
}

#discretetraincountry <- as.factor(countrydis(as.character(newtrain$native.country)))



#Discretize testing set
# discretetestage <- discretize(newtest$age, method = "interval", categories = 10)
# discretetestfnlwgt <- discretize(newtest$fnlwgt, method = "interval", categories = 10)
# discretetestedunum <- discretize(newtest$education.num, method = "interval", categories = 10)
# discretetestgain <- discretize(newtest$capital.gain, method = "interval", categories = 10)
# discretetestloss <- discretize(newtest$capital.loss, method = "interval", categories = 10)
# discretetesthours <- discretize(newtest$hours.per.week, method = "interval", categories = 10)

#discretetestcountry <- as.factor(countrydis(as.character(newtest$native.country)))

#Combine training and testing to make the same intervals for discretizing
newtrain$type <- "train"
newtest$type <- "test"

combined <- rbind(newtrain, newtest)

discreteage <- discretize(combined$age, method = "interval", categories = 10)
discretefnlwgt <- discretize(combined$fnlwgt, method = "interval", categories = 10)
discreteedunum <- discretize(combined$education.num, method = "interval", categories = 10)
discretegain <- discretize(combined$capital.gain, method = "interval", categories = 7) #not enough data
discreteloss <- discretize(combined$capital.loss, method = "interval", categories = 7) #not enough data
discretehours <- discretize(combined$hours.per.week, method = "interval", categories = 10)
discretecountry <- as.factor(countrydis(as.character(combined$native.country)))

combined$age <- discreteage
combined$fnlwgt <- discretefnlwgt
combined$education.num <- discreteedunum
combined$capital.gain <- discretegain
combined$capital.loss <- discreteloss
combined$hours.per.week <- discretehours
combined$native.country <- discretecountry

dim(combined)
newtrain2 <- combined[1:sum(combined$type == "train"), -16]
newtest2 <- combined[(sum(combined$type == "train")+1):nrow(combined), -16]
dim(newtrain2)
dim(newtest2)

#Assignining discretized variables
# newtrain2 <- newtrain
# newtest2 <- newtest
# dim(newtrain2)
# dim(newtest2)
# 
# newtrain2$age <- discretetrainage
# newtrain2$fnlwgt <- discretetrainfnlwgt
# newtrain2$education.num <- discretetrainedunum
# newtrain2$capital.gain <- discretetraingain
# newtrain2$capital.loss <- discretetrainloss
# newtrain2$hours.per.week <- discretetrainhours
# newtrain2$native.country <- discretetraincountry
# 
# newtest2$age <- discretetestage
# newtest2$fnlwgt <- discretetestfnlwgt
# newtest2$education.num <- discretetestedunum
# newtest2$capital.gain <- discretetestgain
# newtest2$capital.loss <- discretetestloss
# newtest2$hours.per.week <- discretetesthours
# newtest2$native.country <- discretetestcountry



#Dummify training set
dumtrainwork <- dummy(newtrain$workclass)
dumtrainedu <- dummy(newtrain$education)
dumtrainmarry <- dummy(newtrain$marital.status)
dumtrainoccu <- dummy(newtrain$occupation)
dumtrainrelation <- dummy(newtrain$relationship)
dumtrainrace <- dummy(newtrain$race)
dumtrainsex <- dummy(newtrain$sex)



#Dummify testing set
dumtestwork <- dummy(newtest$workclass)
dumtestedu <- dummy(newtest$education)
dumtestmarry <- dummy(newtest$marital.status)
dumtestoccu <- dummy(newtest$occupation)
dumtestrelation <- dummy(newtest$relationship)
dumtestrace <- dummy(newtest$race)
dumtestsex <- dummy(newtest$sex)



#Take out columns
newtrain2 <- newtrain2[,-c(2, 4, 6, 7, 8, 9, 10)]
newtest2 <- newtest2[,-c(2, 4, 6, 7, 8, 9, 10)]



#Assigning dummified variables
newtrain2 <- cbind(newtrain2, dumtrainwork, dumtrainedu, dumtrainmarry, dumtrainoccu,
                   dumtrainrelation, dumtrainrace, dumtrainsex)
newtrain2[, 60] <- newtrain2$income
newtrain2 <- newtrain2[,-8]
names(newtrain2)[59]<- "income"
dim(newtrain2)


newtest2 <- cbind(newtest2, dumtestwork, dumtestedu, dumtestmarry, dumtestoccu,
                   dumtestrelation, dumtestrace, dumtestsex)
newtest2[, 60] <- newtest2$income
newtest2 <- newtest2[,-8]
names(newtest2)[59]<- "income"
dim(newtest2)

#fixing...
newtrain2$income <- droplevels(newtrain2$income, c("<=50K.", ">50K."))
newtest2$income <- droplevels(newtest2$income, c("<=50K", ">50K"))

newtest2$income <- as.character(newtest2$income)
newtest2$income <- substr(newtest2$income, 1, nchar(newtest2$income)-1)
newtest2$income <- as.factor(newtest2$income)

dim(newtrain2)
dim(newtest2)
str(newtrain2)
str(newtest2)
```


```{r, eval = FALSE , echo = FALSE}
write.csv(newtest2, file = "../data/cleandata/newtest2.csv", col.names = T, row.names = F)
write.csv(newtrain2, file = "../data/cleandata/newtrain2.csv", col.names = T, row.names = F)
```


```{r}
newtrain2 <- read.csv("../data/cleandata/newtrain2.csv", header = T)
newtest2 <- read.csv("../data/cleandata/newtest2.csv", header = T)
str(newtrain2)
str(newtest2)


#Check if train and test datasets have different factor level
for(i in 1:7){
  cat(names(newtest2)[i], "\n")
  print(levels(newtest2[,i]))
  cat("\n")
  print(levels(newtrain2[,i]))
   cat("\n")
}


#Remove white space in factor variables to visualize factor correctly in the future plots
newtrain3 <- newtrain2
newtest3 <- newtest2
for(i in 1:7){
  newtrain3[,i] <- as.factor(gsub(" ", "", newtrain2[,i], fixed = TRUE))
  newtest3[,i] <- as.factor(gsub(" ", "", newtest2[,i], fixed = TRUE))
}



```

$\\$

$\\$

$\\$

$\\$

#Classification Tree

## Normal way

```{r}

# Fit the tree
tree1 <- tree(income ~., newtrain3)

# brief summary of tree1 object
tree1

# summary of tree1
tree1.summary <- summary(tree1)
tree1.summary


# training accuracy rate
1 - (tree1.summary$misclass[1] / tree1.summary$misclass[2])

# Make plot of the tree
plot(tree1)
text(tree1, pretty= T)


set.seed (100)

income <- newtest3$income

treepred <- predict (tree1, newtest3, type = "class")
table <- table(treepred ,income)
table

# Misclassification Rate for test dataset
( table[1, 2] + table[2, 1] ) / sum(table)


# Accuracy Rate for test dataset
( table[1, 1] + table[2, 2] ) / sum(table)

set.seed(100)
cv.tree1 <- cv.tree(tree1, FUN=prune.misclass)
cv.tree1


# Plot the error rate as a function of both size and cost complexity parameter.

par(mfrow = c(1, 2))
plot(cv.tree1$size, cv.tree1$dev, type="b", xlab = "size", ylab = "CV error")
plot(cv.tree1$k, cv.tree1$dev, type="b",  xlab = "cost-complexity parameter", ylab = "CV error")

# Get the best number of node of tree
best <- cv.tree1$size[which(cv.tree1$dev == min(cv.tree1$dev))[1]]
best

# prune the tree
prune.tree1 <- prune.misclass(tree1, best = best)
plot(prune.tree1)
text(prune.tree1, pretty =T)


# Performance of pruned tree on the test dataset
treepred <- predict(prune.tree1 , newtest3 ,type = "class")
table <- table(treepred, income)
table

# Misclassification Rate of prunned tree
( table[1, 2] + table[2, 1] ) / sum(table)


# Accuracy Rate of prunned tree
( table[1, 1] + table[2, 2] ) / sum(table)

```


## other way to tune

```{r}

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
set.seed(100)


# Training the Decision Tree classifier with criterion as information (cross Entropy)
dtree_fit <- caret::train(income ~., data = newtrain3,
                          method = "rpart",
                   parms = list(split = "information"),
                   trControl = trctrl,
                   tuneLength = 10)


dtree_fit


# Tuning parameter - cp
dtree_fit$bestTune

# plot classification tree  - part of the factor names are missing ******
prp(dtree_fit$finalModel, box.palette = "Reds", tweak = 0.8, 
    fallen.leaves = FALSE, faclen = 0, extra = 1)


# prediction
testpred <- predict(dtree_fit, newdata = newtest3)
confusionMatrix(testpred, newtest3$income)  #check accuracy


#Training the Decision Tree classifier with criterion as gini index
set.seed(100)
dtree_fit_gini <- caret::train(income ~., data = newtrain3, method = "rpart",
                   parms = list(split = "gini"),
                   trControl=trctrl,
                   tuneLength = 10)
dtree_fit_gini


#Plot decision tree from gini index criterion
prp(dtree_fit_gini$finalModel, box.palette = "Blues", tweak = 0.6)

#Tuning parameter - cp
dtree_fit_gini$bestTune

#Accuracy and confusion matrix from Gini index criterion
test_pred_gini <- predict(dtree_fit_gini, newdata = newtest3)
confusionMatrix(test_pred_gini, newtest3$income )  #check accuracy

#ROC Curve  : https://stackoverflow.com/questions/30818188/roc-curve-in-r-using-rpart-package


#Getting predicted >50K of income probabilities 
gini_prob <- predict(dtree_fit_gini, newdata = newtest3, type = "prob")[,2]
gini_prediction <- prediction(gini_prob, newtest3$income)
gini_performance <- performance(gini_prediction, measure = "tpr", x.measure = "fpr")

#Plot ROC curve 
plot(gini_performance, main="ROC curve")
abline(a=0, b=1, lty=2)


#Calculate AUC
performance(gini_prediction, measure="auc")@y.values[[1]]

#Pick the best threshold
str(gini_performance)
cutoffs <- data.frame(cut = gini_performance@alpha.values[[1]], 
                      fpr = gini_performance@x.values[[1]], 
                      tpr = gini_performance@y.values[[1]])
head(cutoffs)
roc <- pROC::roc(newtest3$income, gini_prob)
threshold <- coords(roc, "best", ret = "threshold")
cat("The best threshold is :  " , threshold, "\n")


#Get accuracy rate of testset data using the optimal threshold  ****
confusionMatrix(table(gini_prob > threshold, newtest3$income == ">50K"))
confusionMatrix(gini_prob > threshold, newtest3$income == ">50K")



```



## Using R part

<threshold>
https://stackoverflow.com/questions/46042966/set-threshold-for-the-probability-result-from-decision-tree

```{r}

set.seed(100)

# Classification tree using cross entropy criterion
tree <- rpart(income ~., data = newtrain3, 
              control = rpart.control(cp = 0.004), method = "class",
              parms = list(split = 'information') )
  # minsplit = 2, minbucket = 1


#Pick the optimal tuning parameter
cp <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]


#Prune the tree using the optimal cp
treepruned <- prune(tree, cp = cp)

#Treepruned object
treepruned

printcp(treepruned)

#summary information
summary(treepruned, digits = 3)


#rpart tree
rpart.plot(treepruned)


#Confusion matrix - train data
confusionMatrix(newtrain3$income, predict(treepruned, newdata = newtrain3,
                                          type="class"))



#Confusion matrix - test data
confusionMatrix(newtest3$income,  predict(treepruned, newdata = newtest3,
                                          type="class"))


```



## Tune more parameters  by information gain (cross entropy) splitting criterion - minsplit, minbucket, and cp
```{r, eval = FALSE, echo = FALSE}


#Create a task
trainTask <- makeClassifTask(data = newtrain3, target = "income", positive = ">50K")
testTask <- makeClassifTask(data = newtest3, target = "income", positive = ">50K")

# Brief view of trainTask
trainTask

# For deeper View
str(getTaskData(trainTask))


#normalize the variables
# trainTask <- normalizeFeatures(trainTask,method = "standardize")
# testTask <- normalizeFeatures(testTask,method = "standardize")


#Feature importance
# im_feat <- generateFilterValuesData(trainTask, method = c("information.gain","chi.squared"))
# plotFilterValues(im_feat,n.show = 20)


getParamSet("classif.rpart")

#set 3 fold cross validation
setcv <- makeResampleDesc("CV", iters = 3)

#Make tree learner with information gain(cross entropy) splitting criterion
makeatree <- makeLearner("classif.rpart", 
                         parms = list(split = "information"), 
                         predict.type = "response")


#Search for hyperparameters (Specifying the search space)
gs <- makeParamSet(
    makeIntegerParam("minsplit", lower = 10, upper = 50),
    makeIntegerParam("minbucket", lower = 5, upper = 50),
    makeNumericParam("cp", lower = 0.001, upper = 0.2)
)


#Grid search
gscontrol <- makeTuneControlGrid()

#Hypertune the parameters - takes a while so keep it as comment
stune <- tuneParams(learner = makeatree, resampling = setcv, task = trainTask, par.set = gs, control = gscontrol, measures = acc)


#CV accuracy from cross validation
stune$y

#Tuned hyper-parameters
stune$x

#Use tuned hyperparameters for modeling
ttree <- setHyperPars(makeatree, par.vals = stune$x)


#train the model
trpart <- train(ttree, trainTask)

getLearnerModel(trpart)

#plot classification tree
prp(trpart$learner.model, box.palette = "Reds", tweak = 2.5, 
     faclen = 0, extra = 1)


#Predictions from the model with hypertuned parameters on train dataset
tpmodel1 <- predict(trpart, trainTask)
#predicted income from the model
tpmodel1$data$response


#Confusion matrix - train data
confusionMatrix(newtrain3$income, tpmodel1$data$response)


#Predictions from the model with hypertuned parameters on test dataset
tpmodel2 <- predict(trpart, testTask)
#predicted income from the model
tpmodel2$data$response


#Confusion matrix - test data
confusionMatrix(newtest3$income, tpmodel2$data$response)



```



## Tune more parameters  by gini index splitting criterion - minsplit, minbucket, and cp


```{r, eval = FALSE, echo = FALSE}

#normalize the variables
# trainTask <- normalizeFeatures(trainTask,method = "standardize")
# testTask <- normalizeFeatures(testTask,method = "standardize")


#Feature importance
# im_feat <- generateFilterValuesData(trainTask, method = c("information.gain","chi.squared"))
# plotFilterValues(im_feat,n.show = 20)


getParamSet("classif.rpart")

#Make tree learner with information gain(cross entropy) splitting criterion
makeatree2 <- makeLearner("classif.rpart", predict.type = "response", 
                         parms = list(split = "gini"))

#set 3 fold cross validation
setcv <- makeResampleDesc("CV",iters = 3L)

#Search for hyperparameters (Specifying the search space)
gs <- makeParamSet(
    makeIntegerParam("minsplit",lower = 10, upper = 50),
    makeIntegerParam("minbucket", lower = 5, upper = 50),
    makeNumericParam("cp", lower = 0.001, upper = 0.2)
)


#Grid search
gscontrol <- makeTuneControlGrid()

# ** Hypertune the parameters - takes a while so keep it as comment
stune2 <- tuneParams(learner = makeatree2, resampling = setcv, task = trainTask, par.set = gs, control = gscontrol, measures = acc)


#CV accuracy from cross validation
stune2$y

#Tuned hyper-parameters
stune2$x

#using hyperparameters for modeling
ttree <- setHyperPars(makeatree2, par.vals = stune2$x)


#train the model
trpart <- train(ttree, trainTask)


getLearnerModel(trpart)

#plot classification tree
prp(trpart$learner.model, box.palette = "Reds", tweak = 2.5, 
     faclen = 0, extra = 1)


#Predictions from the model with hypertuned parameters on train dataset
tpmodel3 <- predict(trpart, trainTask)
#predicted income from the model
head(tpmodel3$data$response)


#Confusion matrix - train data
confusionMatrix(newtrain3$income, tpmodel3$data$response)


#Predictions from the model with hypertuned parameters on test dataset
tpmodel4 <- predict(trpart, testTask)
#predicted income from the model
head(tpmodel4$data$response)


#Confusion matrix - test data
confusionMatrix(newtest3$income, tpmodel4$data$response)



```




$\\$

$\\$

$\\$

$\\$

#Bagged Tree - simply a special case of a random forest with m = p.
```{r}
set.seed(100)

n <- dim(newtrain3)[2]

bagged <- randomForest(income ~., data = newtrain3, mtry = n,
                       importance = TRUE)
bagged


bagged_class = predict(bagged ,newdata = newtest3)
plot(bagged_class, newtest3[, n])
abline (0,1)
mean((bagged_class - newtest3[, n])^2)

```



#Random Forest
```{r}



```


















